{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\91844\\anaconda3\\lib\\site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Requirement already satisfied: mtcnn in c:\\users\\91844\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from mtcnn) (2.4.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from mtcnn) (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (1.20.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\91844\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (5.4.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\91844\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\91844\\anaconda3\\lib\\site-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
      "Requirement already satisfied: tensorflow==2.2 in c:\\users\\91844\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.20.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (3.17.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (0.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (2.10.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (2.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (0.36.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.38.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorflow==2.2) (1.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.30.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.25.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.1)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.1+cpu in c:\\users\\91844\\anaconda3\\lib\\site-packages (1.8.1+cpu)\n",
      "Requirement already satisfied: torchvision==0.9.1+cpu in c:\\users\\91844\\anaconda3\\lib\\site-packages (0.9.1+cpu)\n",
      "Requirement already satisfied: torchaudio===0.8.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\91844\\anaconda3\\lib\\site-packages (from torch==1.8.1+cpu) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\91844\\anaconda3\\lib\\site-packages (from torch==1.8.1+cpu) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from torchvision==0.9.1+cpu) (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install mtcnn\n",
    "!pip install tensorflow==2.2\n",
    "!pip3 install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "#from model import Net\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch===1.7.0 torchvision===0.8.1 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    '''\n",
    "    function to load saved model\n",
    "    '''\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # as we've to perform testing, we don't need backpropagation so setting 'requires_grad' as false\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    # model.eval() ->  .eval() does not change any behaviour of gradient calculations , but are used to set specific layers\n",
    "    #                  like dropout and batchnorm to evaluation mode i.e. dropout layer won't drop activations and \n",
    "    #                  batchnorm will use running estimates instead of batch statistics.\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.Resize((224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing file paths for both the models\n",
    "filepath1 = '../Saved Models/Real-Time Corona Mask Detection Model.pth'\n",
    "filepath2 = '../Saved Models/Facial Keypoints Model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torchvision.models.resnet.Bottleneck' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\91844\\anaconda3\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LogSoftmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Loading the models for testing\n",
    "loaded_model_mask = load_checkpoint(filepath1)\n",
    "#net = Net()\n",
    "#net.load_state_dict(torch.load(filepath2))\n",
    "#for parameter in net.parameters():\n",
    "#        parameter.requires_grad = False\n",
    "#net.eval()\n",
    "#loaded_model_landmark = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using GPU if available else using CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face-alignment in c:\\users\\91844\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (1.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (1.20.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (0.18.1)\n",
      "Requirement already satisfied: numba in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (0.53.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (4.5.2.52)\n",
      "Requirement already satisfied: torch in c:\\users\\91844\\anaconda3\\lib\\site-packages (from face-alignment) (1.8.1+cpu)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91844\\anaconda3\\lib\\site-packages (from numba->face-alignment) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from numba->face-alignment) (0.36.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from scikit-image->face-alignment) (3.3.4)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from scikit-image->face-alignment) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from scikit-image->face-alignment) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from scikit-image->face-alignment) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from scikit-image->face-alignment) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from scikit-image->face-alignment) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\91844\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\91844\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image->face-alignment) (5.0.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\91844\\anaconda3\\lib\\site-packages (from torch->face-alignment) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install face-alignment\n",
    "import face_alignment\n",
    "from skimage import io\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D , flip_input=False , device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "font_scale = 0.8\n",
    "thickness = 1\n",
    "red = (0,0,255)\n",
    "green = (0,255,0)\n",
    "blue = (255,255,0)\n",
    "yellow = (255,255,255)\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    # getting the frame in 'frame' and a bool value in 'ret' which is true if a frame is returned\n",
    "    ret, frame = cap.read()\n",
    "    size = frame.shape\n",
    "    if ret == True:\n",
    "        # converting into grayscale for feature reduction and grayscale images are less computation intensive to operate on\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        col = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # detecting the faces in the frame returned, it will return the coords of bounding box along with its height and width\n",
    "        result = detector.detect_faces(col)\n",
    "        \n",
    "        for box in result:\n",
    "            x, y, w, h = box['box']\n",
    "            keypoints = box['keypoints']\n",
    "            #2D image points. If you change the image, you need to change vector\n",
    "            x1 = keypoints['mouth_right'][0]\n",
    "            x2 = keypoints['mouth_left'][0]\n",
    "            y1 = keypoints['mouth_right'][1]\n",
    "            y2 = keypoints['mouth_right'][1]\n",
    "            import math\n",
    "            # drawing the bounding box based on the coordinates provided by haar_cascade\n",
    "            preds = fa.get_landmarks(frame)\n",
    "            \n",
    "            midpoint_x = (x1+x2)/2\n",
    "            midpoint_y = (y1+y2)/2\n",
    "            ######distance#####\n",
    "            dist = math.sqrt(math.pow((x1-x2),2)+math.pow((y1-y2),2))\n",
    "            chin = (midpoint_x-math.sqrt(midpoint_y) , midpoint_y+5+(math.sqrt(y1+y2)-math.sqrt(x1+x2)))\n",
    "            chin = (preds[2][2][0],preds[2][2][1])\n",
    "            #print(preds)\n",
    "            image_points = np.array([\n",
    "                            (keypoints['nose']),     # Nose tip\n",
    "                            (chin),     # Chin\n",
    "                            (keypoints['left_eye']),     # Left eye left corner\n",
    "                            (keypoints['right_eye']),     # Right eye right corne\n",
    "                            (keypoints['mouth_left']),     # Left Mouth corner\n",
    "                            (keypoints['mouth_right'])      # Right mouth corner\n",
    "                        ], dtype=\"double\")\n",
    " \n",
    "            # 3D model points.\n",
    "            model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                           (0.0, -330.0, -65.0),  \n",
    "                              #(0.0,0.0,0.0),# Chin65\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner                     \n",
    "                        ])\n",
    "\n",
    "            # Camera internals\n",
    "            focal_length = size[1]\n",
    "            center = (size[1]/2, size[0]/2)\n",
    "            camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    "                         )\n",
    "            print (\"Camera Matrix :\\n {0}\".format(camera_matrix))\n",
    "\n",
    "            import matplotlib.pyplot as plt\n",
    "            dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "            # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "            # We use this to draw a line sticking out of the nose\n",
    "            (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "            p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "            p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), 2)\n",
    "            # cropping the portion of image covered by the bounding box\n",
    "            cropped_img = frame[y:y+h+2, x:x+w+2]\n",
    "            # using Python's PIL lib to read image back into RGB format\n",
    "            pil_image = Image.fromarray(cropped_img, mode=\"RGB\")\n",
    "            pil_image = train_transforms(pil_image)\n",
    "            image = pil_image.unsqueeze(0)\n",
    "            # feeding the test cropped image into the model\n",
    "            result = loaded_model_mask(image)\n",
    "            img = np.array(image)\n",
    "            img = img[:,0,:,:]\n",
    "            img = img.reshape(img.shape[0], 1, img.shape[1], img.shape[2])\n",
    "            #result_lm = loaded_model_landmark(torch.from_numpy(img))\n",
    "            #result_lm = np.array(result_lm)\n",
    "            #result_lm = result_lm*(0.19*h)\n",
    "            #result_lm = result_lm.reshape(68,2)\n",
    "            #result_lm[:,0] += x+(0.28*h)\n",
    "            #result_lm[:,1] += y+(0.49*w)\n",
    "            _, maximum = torch.max(result.data, 1)\n",
    "            prediction = maximum.item()\n",
    "            preds = fa.get_landmarks(frame)\n",
    "            \n",
    "            print(preds)\n",
    "            # displaying results based on classification\n",
    "            if prediction == 0:\n",
    "                cv2.line(frame, p1, p2, (255,0,0), 2) \n",
    "                preds = fa.get_landmarks(frame)\n",
    "                for i in preds:\n",
    "                    for j in i:\n",
    "                        cv2.circle(frame,(int(j[0]),int(j[1])), 1, yellow, 1)\n",
    "                cv2.putText(frame, \"Correctly Masked\", (x-33,y-10), font, font_scale, green, thickness)\n",
    "                cv2.rectangle(frame, (x, y), (x+w+2, y+h+2), green, 2)  # green colour rectangle if mask is worn correctly\n",
    "            elif prediction == 1:\n",
    "                cv2.line(frame, p1, p2, (255,0,0), 2) \n",
    "                for i in preds:\n",
    "                    for j in i:\n",
    "                        cv2.circle(frame,(int(j[0]),int(j[1])), 1, yellow, 1)\n",
    "                cv2.putText(frame, \"Unmasked\", (x,y-10), font, font_scale, red, thickness)\n",
    "                cv2.rectangle(frame, (x, y), (x+w+2, y+h+2), red, 2)   # red colour rectangle if mask is not being worn\n",
    "            elif prediction == 2:\n",
    "                cv2.line(frame, p1, p2, (255,0,0), 2) \n",
    "                preds = fa.get_landmarks(frame)\n",
    "                for i in preds:\n",
    "                    for j in i:\n",
    "                        cv2.circle(frame,(j[0],j[1]), 1, yellow, 1)\n",
    "                cv2.putText(frame, \"Incorrectly Masked\", (x-37,y-10), font, font_scale, blue, thickness)\n",
    "                cv2.rectangle(frame, (x, y), (x+w+2, y+h+2), blue, 2)   # blue colour rectangle if mask is not worn correctly\n",
    "        cv2.imshow('frame', frame)\n",
    "        if (cv2.waitKey(1) & 0xFF) == ord('q'):  # press 'q' to exit\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
